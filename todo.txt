1.[✓] Einlesen und Vorverarbeitung
    1.1 [✓] Einlesen der Daten aus titanic.csv
    1.2 [✓] Speichern der Daten in einer geeigneten Datenstruktur:
        linked-list
        vector<tuple<Num(int),Survived(bool),Pclass(int),Sex(bool),Age(int)Siblings(int),Parents(int),Fare(float)>>
        oder struct (ist wahrscheinlich einfacher...)

    1.2.2 [✓] Strukturieren der Daten:
        - Entfernen von irrelevanten Spalten -> Name
        - trennen der datenpunkte (daten sind durch , getrennt)

2. Entscheidungsbaum erstellen (Training)
    2.1 Einlesen der Hyperparameter des Algorithmus (maximale Tiefe des Baumes)
    2.2 Implementierung des CART-Algorithmus:
        2.2.1 Berechnung des Gini-Index für ein Attribut
            [✓] Berechnung wahrscheinlich überleben
        2.2.2 [✓]Auswahl des Attributs mit dem niedrigsten Gini-Index
        2.2.3 [✓]Aufteilen des Vectors
        2.2.4 [ ]Rekursive Anwendung

    2.3 = Trainieren des Entscheidungsbaums mit den Trainingsdaten

3. Vorhersage treffen (Inferenz)
    3.1 Einlesen der Daten der zu testenden Person
    3.2 Durchlaufen des Entscheidungsbaums und Treffen einer Vorhersage basierend auf den Attributen der Person




Based on the provided code snippets, here are some potential issues I identified:

1. Handling of Missing Values:

The code doesn't explicitly handle missing values in the passenger data. This could lead to unexpected behavior or inaccurate predictions if the data contains missing attributes. It's important to implement a strategy for handling missing values, such as imputation or exclusion.

2. Overfitting:

The algorithm trains a CART decision tree without any explicit measures to prevent overfitting. Overfitting occurs when the model learns the training data too well and fails to generalize to unseen data. Techniques like pruning or cross-validation can be used to mitigate overfitting.

3. Feature Importance:

The code doesn't provide any information about the importance of different features in the prediction. Understanding which features are most influential can be valuable for interpreting the model and potentially improving its performance.

4. Confidence Calculation:

The confidence calculation for the leaf nodes seems to be based solely on the survival proportion. This might not be the most accurate way to estimate confidence, especially for small datasets or imbalanced classes. More sophisticated methods for confidence estimation could be explored.

5. Memory Management:

The code allocates memory for new TreeNode objects but doesn't explicitly deallocate them when they are no longer needed. This could lead to memory leaks if the program runs for a long time or processes large datasets.

6. Error Handling:

The code doesn't have robust error handling for potential issues like invalid input or file reading errors. Implementing proper error handling can make the program more reliable and user-friendly.

7. Code Clarity and Documentation:

The code could benefit from improved clarity and documentation. Adding comments and meaningful variable names would make the code easier to understand and maintain.

8. Efficiency:

The code doesn't seem to be optimized for efficiency, especially for large datasets. Techniques like data structures and algorithms could be used to improve the performance of the algorithm.

9. User Interface:

The user interface for inputting passenger data and displaying predictions is quite basic. A more user-friendly interface could be implemented using libraries or frameworks for graphical user interfaces.

10. Testing:

The code doesn't include any unit tests or other forms of automated testing. Implementing tests can help ensure the correctness and robustness of the algorithm.

Overall, the provided algorithm has potential but could be improved by addressing the issues mentioned above. Implementing these improvements would make the algorithm more accurate, reliable, efficient, and user-friendly.